{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration and Tips\n",
        "\n",
        "This guide covers optional configuration settings and best practices to enhance your experience with Neurodent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logging Configuration\n",
        "\n",
        "By default, Neurodent operations run quietly. If you want to monitor progress and see detailed information about what Neurodent is doing, you can configure Python's logging system.\n",
        "\n",
        "This is especially useful for:\n",
        "- Long-running analyses to track progress\n",
        "- Debugging issues with data loading or processing\n",
        "- Understanding what happens during each step of the pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import logging\n",
        "\n",
        "# Configure logging to display progress and debug information\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\", \n",
        "    level=logging.INFO,  # Change to logging.DEBUG for more detailed output\n",
        "    stream=sys.stdout\n",
        ")\n",
        "logger = logging.getLogger()\n",
        "\n",
        "print(\"Logging configured! You'll now see progress messages from Neurodent.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logging Levels\n",
        "\n",
        "You can adjust the logging level to control how much information is displayed:\n",
        "\n",
        "- `logging.DEBUG` - Most detailed, shows all internal operations\n",
        "- `logging.INFO` - Shows progress and important steps (recommended)\n",
        "- `logging.WARNING` - Only shows warnings and errors\n",
        "- `logging.ERROR` - Only shows errors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Temporary Directory Configuration\n",
        "\n",
        "Neurodent uses a temporary directory for intermediate files during processing. You can configure this location if you need to:\n",
        "- Use a location with more disk space\n",
        "- Use a faster storage device (e.g., SSD)\n",
        "- Keep temporary files in a specific location\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neurodent import core\n",
        "\n",
        "# Set a custom temporary directory\n",
        "# core.set_temp_directory(\"/path/to/your/temp/dir\")\n",
        "\n",
        "# Check the current temp directory\n",
        "print(f\"Using temp directory: {core.get_temp_directory()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Tips\n",
        "\n",
        "### Memory Management\n",
        "\n",
        "For large datasets, consider:\n",
        "- Processing data in smaller time windows\n",
        "- Using the caching features to avoid recomputing results\n",
        "- Closing Python and restarting between analyses to free up memory\n",
        "\n",
        "### Parallel Processing\n",
        "\n",
        "Many Neurodent functions support parallel processing. Check the function documentation for `n_jobs` parameters that allow you to use multiple CPU cores.\n",
        "\n",
        "### HPC and Workflow Management\n",
        "\n",
        "For large-scale analyses across many animals and conditions, consider using Neurodent's Snakemake pipeline on a high-performance computing (HPC) cluster. This allows you to:\n",
        "- Process multiple animals in parallel\n",
        "- Automatically manage dependencies between analysis steps\n",
        "- Resume interrupted workflows without recomputing completed steps\n",
        "- Scale to hundreds of recordings\n",
        "\n",
        "See the [Snakemake Pipeline Tutorial](../tutorials/snakemake_pipeline.html) for a complete guide to setting up and running Neurodent on an HPC cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you've configured Neurodent, explore the tutorials:\n",
        "\n",
        "- [Basic Usage](basic_usage.ipynb) - Complete workflow from data loading to visualization\n",
        "- [Data Loading](data_loading.ipynb) - Learn about loading data from different formats\n",
        "- [Tutorials](../tutorials/index.html) - More advanced analysis techniques\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
